{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries that are generally imported for any deep learning model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# libraries need to prepare the data\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "\n",
    "# libraries required to build the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# libraries for activation functions required\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.activations import softmax\n",
    "\n",
    "# weight initializer libraries\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.initializers import HeUniform\n",
    "\n",
    "# optimizer library\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# callback library\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the random seed to generalize the output\n",
    "# the seed value is used to generate the random number generator. \n",
    "# And, every time you use the same seed value, you will get the same random values.\n",
    "\n",
    "# setting random seed in numpy\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "# setting random seed in tensorflow\n",
    "tf.random.set_seed(2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object of the ImageDataGenerator class\n",
    "# the ImageDatagenerator class helps in image augmentation by allowing us to apply different transforms to our images\n",
    "# for example: rescale - normaizes the value of each colour channel(R or G or B) of each pixel between 0 and 1\n",
    "#              shear range - shears images by a certain amount ( value accepted is between 0 and 1)\n",
    "#              rotation range - rotates images by a certain amount\n",
    "#              zoom range - allows us to zoom images\n",
    "#              horizontal and vertical flip - flips images by in directions named to produce input randomness\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                    shear_range=0.2,\n",
    "                                    rotation_range=2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\91918\\\\Desktop\\\\Forest_fire_prediction'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "# we now use the flow_from_directory function from the ImageDataGenerator class\n",
    "# this function allows us to import our dataset consisting of images from a directory/folder\n",
    "# target_size - resizes the images according to the input shape of the model\n",
    "# class mode - using categorical class mode since we have a multiclass classification\n",
    "# batch_size - gives batches of images as input to the model instead of single images\n",
    "training_set = train_data_gen.flow_from_directory(directory=\"C:/Users/91918/Desktop/Forest_fire_prediction/dataset/train\",\n",
    "                                                  target_size=(224,224),\n",
    "                                                  class_mode='categorical',\n",
    "                                                  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating another object of ImageDataGenerator class\n",
    "# here we do not apply any transformations because we want our validation data to be absolutely new to our model ( i.e. unprepared) \n",
    "# we only rescale the pixel values to normalize them between 0 and 1\n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing our validation set images with the same image size and batch size\n",
    "validation_set = validation_data_gen.flow_from_directory(directory=\"../input/brain-tumor-mri-dataset/Testing\",\n",
    "                                                        target_size=(224,224),\n",
    "                                                        class_mode='categorical',\n",
    "                                                        batch_size=32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next function iterates over the training set and separates the images and their labels \n",
    "imgs, labels = next(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define a function that prints the first 10 images from the training set \n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling our function to print the first 10 images\n",
    "plotImages(imgs)\n",
    "# printing all the labels from the first batch of 32 images\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Sequential() helps make a sequential model. \n",
    "# A sequential model is a model which consists of a sequence of layers.\n",
    "model = Sequential()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a Conv2D layer\n",
    "# Conv2D is a function for the convolutional layer \n",
    "# In a convolutional layer, multiple filters are applied on each image to highlight key features from the particular image\n",
    "# after the applying the filters the image is called a feature map\n",
    "# here we apply 32 filters to each image and our filters are 3x3 matrices which is the kernel_size\n",
    "# we give our activation function as ReLU. This is one the best activation functions because it helps prevent Vanishing Gradient Problem during the backpropagation stage\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size=3,\n",
    "                 activation=relu,\n",
    "                 input_shape=[224, 224, 3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a secong convolutional layer\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size=3,\n",
    "                 activation=relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the first MaxPool2D layer\n",
    "# MaxPool2D is a function for the max pooling layer\n",
    "# In the max pooling layer we apply a kernel to the feature maps which preserves only the highlighted portions on the images\n",
    "# there are other types of pooling like minPooling, avgPooling, etc.\n",
    "# here we use pool_size 2 which decides the size of the matrix(area) from which we select the highest value(max pooling)\n",
    "# strides - this is the number of places the kernel will move after taking max from one area ( the kernel moves from left to right)\n",
    "# padding - while moving if our kernel faces empty places within it when at one edge of the feature map, then it uses padding by applying zero values to those places\n",
    "model.add(MaxPool2D(pool_size=2,\n",
    "                    strides=2,\n",
    "                    padding='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding another Conv2D layer\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size=3,\n",
    "                 activation=relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a fourth Conv2D layer\n",
    "model.add(Conv2D(filters=64,\n",
    "                 kernel_size=3,\n",
    "                 activation=relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a second MaxPool2D layer \n",
    "model.add(MaxPool2D(pool_size=2,\n",
    "                    strides=2,\n",
    "                    padding='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a Flatten layer\n",
    "# the Flatten() layer is used to flatten the output from the last layer to prepare it for input to the upcoming fully connected layers\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #adding the first Dense layer\n",
    "# this is our first fully connected layer which allows the model to train itself by adjusting the weights and biases\n",
    "# neurons - this is the number of neurons that are present in this layer. Here we use 32 neurons (experimental value)\n",
    "# activation - we use ReLU \n",
    "# use_bias - we set this to true as we want to use a bias value \n",
    "# kernel_initializer - this is used to initialize the weights at the beginning of the training\n",
    "#                      There are many types of weight initializers like Xavier/Gorat (Uniform & Normal) or He (Uniform & Normal), etc. \n",
    "model.add(Dense(units=32,\n",
    "                activation=relu,\n",
    "                use_bias=True\n",
    "#                 kernel_initializer=HeNormal()\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are using a Dropout layer\n",
    "# A dropout layer disables some randomly chosen neurons by making their input weights zero during training.\n",
    "# During testing, these connections are reconnected.\n",
    "# we use a dropout layer to prevent overfitting because sometimes the model gets too dependent on some particular neurons\n",
    "# and thus gets overfitted.\n",
    "model.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding another fully connected layer\n",
    "model.add(Dense(units=16,\n",
    "                activation=relu,\n",
    "                use_bias=True\n",
    "#                 kernel_initializer=HeUniform()\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our output layer. \n",
    "# We use 4 neurons in our layer since ours is a multiclass classification and we have 4 categories to classify between.  \n",
    "model.add(Dense(units=4,\n",
    "                activation=softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the details of our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the compilation stage. \n",
    "# We use the compile()\n",
    "# optimizer - here we give an optimizer function which is currently one of the best optimizers as it uses both a momentum (weighted average) for noise reduction and \n",
    "#             also uses an adaptive learning rate\n",
    "# loss - we use the categorical_crossentropy to calculate our loss as we have multiclass classification\n",
    "# metrics - we use accuracy as a measure of performance of our model\n",
    "model.compile(optimizer=Adam(),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping - this is a callback function which stops the training of the model based on the monitored parameter\n",
    "# monitor - parameter to be monitored\n",
    "# min_delta - Minimum change in the monitored quantity to qualify as an improvement\n",
    "# patience - Number of epochs with no improvement after which training will be stopped.\n",
    "# verbose - messages to be displayed\n",
    "# mode - One of {\"auto\", \"min\", \"max\"}. In min mode, training will stop when the quantity monitored has stopped decreasing; \n",
    "#        in \"max\" mode it will stop when the quantity monitored has stopped increasing; \n",
    "#        in \"auto\" mode, the direction is automatically inferred from the name of the monitored quantity.\n",
    "# baseline - Baseline value for the monitored quantity. Training will stop if the model doesn't show improvement over the baseline.\n",
    "# restore_best_weights - Whether to restore model weights from the epoch with the best value of the monitored quantity. \n",
    "#                        If False, the model weights obtained at the last step of training are used.\n",
    "\n",
    "# early_stopper = EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     min_delta=0,\n",
    "#     patience=0,\n",
    "#     verbose=0,\n",
    "#     mode='auto',\n",
    "#     baseline=None,\n",
    "#     restore_best_weights=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we train the model using the fit()\n",
    "# x - the training data\n",
    "# vaidation_data - data against which the model accuracy will be calculated after training\n",
    "# epochs - number of times the model will train on the whole dataset to improve its performance. Here the value 60 is completely experimental.\n",
    "# verbose - determines verbosity. types of messages to display.\n",
    "\n",
    "model_history = model.fit(x=training_set,validation_data=validation_set,epochs=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this a callback from the model. the history gets returnes by the fit() used to train the model \n",
    "# the history of the model contains all details of its implementation such as the weights, keys, etc.\n",
    "# here we see the keys which evaluate the model\n",
    "model_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the training and testing accuracy\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('Accuracy of the model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing training and testing loss \n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('Loss of the model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['glioma','meningioma','normal','adenoma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image1 = load_img('../input/brain-tumor-mri-dataset/Testing/glioma/Te-glTr_0002.jpg',target_size = (224,224))\n",
    "test_image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image2 = load_img('../input/brain-tumor-mri-dataset/Training/notumor/Tr-noTr_0003.jpg',target_size = (224,224))\n",
    "test_image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image2 = img_to_array(test_image2)\n",
    "test_image2 = np.expand_dims(test_image2,axis=0)\n",
    "result2 = np.argmax(model.predict(test_image2/255.0),axis=1)\n",
    "print(index[result2[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4690f8c88f3573a1dc2c8030cefea463026d8c098ffd1aba20914e76c07a1d7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
